okay hey everyone david shapiro here we are getting started with the inaugural episode of the cognitive ai lab podcast so just about four or five days ago i started um a discord channel by popular demand from my youtube channel and um just four days later we've got 100 people in and there's so many good discussions that several members asked if we could do a podcast just to kind of summarize what we're talking about because it's so much to keep up with and everyone jumped on you see we've got a full house today so first i will introduce the rules of the of the server and then the format of the podcast so the rules are very simple keep it cool and be kind this is meant to be a chill place rule number two is discussion not debate we're not trying to prove anyone right or wrong the key is just to learn and share and in line with that agree to disagree we've got all different kinds of people with all different kinds of experiences and specializations we've got theologians we've got atheists we've got people that specialize in technology we've got artists we've got all kinds of different perspectives and so we're not always going to agree and that's fine and then and an extension from that is the importance of beliefs and evidence and that is we all share our own beliefs and evidence and we respect other people's beliefs and evidence and we just leave it at that and uh and that's fine um okay so with the rules the format let me get back to the format so what we're gonna do is this is a format that is really common in um in different kinds of groups and it's a format that i learned from my science fiction and fantasy uh writing group so what we're going to do is we're going to have one presenter just kind of spend you know 10 15 20 minutes sharing their idea we can drop some questions in the chat just so that we don't have to interrupt and then what we'll do is once once the presenter is done we'll have a round robin where everyone will get one chance to you know one to two minutes to just kind of share their perspective their questions um and then after that we'll move to phase three which will be uh just an open open format discussion but before we get started um since we've got everyone here we will go ahead and introduce ourselves um and uh i just wanted to reiterate not everyone is going to participate that's fine some people um just want to just want to listen um and so we'll pat we'll give them a pass if they don't want to participate that's fine just let me know in the chat down here um and anyways okay so uh to start the introductions my name is david shapiro i've been in technology since 2007. i started researching artificial intelligence independently in about 2009 i've been following the progress of deep learning ever since and then once gpt2 came out everything started really changing gpt3 came out and the rest is history and that's that's why i'm here today um i started sharing everything that i do on youtube and it really took off basically what i do is pair programming sessions and everyone seems to love that you all love seeing me fiddle through and and take a wild stab at these things so that's that's how i got here um let's see i'll just go down the list on the left side so christopher if you'd like to uh um just introduce yourself real quick and um and we'll go from there hello um christopher collin tuno i sound good don't i yup perfect okay great i fixed it um well i'm 35 and i've been working with tech since just being a little kid and i've always tried to get involved with the most cutting-edge tech i have a vested interest specifically with natural language models as they i see is there something that we know they're going to be the future of what's building out later in tech um so yeah no i wasn't uh give them give them your background oh oh hi i'm christopher's wife melody um we're sharing a mic because our computers are literally three feet apart yeah so i'm in i'm in to show you that i'm there but i'll be lighting up as christopher um i'm his wife uh we have a background in religious philosophy and um we started on this journey about 15 years ago when we wanted information and knowledge to be able to be passed around more freely um and that's kind of where our journey began and we've theorized and philosophized about how information could be transmitted freely and to everyone and over the past 15 years that's led us to blockchain and homomorphic encryption and um ultimately led us to dave's channel where he is tinkering with um uh prompt engineering which has been really helpful and um yeah now we're here excellent yeah they've also been working with legal law and how to get this type of technology implemented in government excellent yeah um so i'll just give a brief preview so christopher will be our present our first presenter tonight and we might just do one topic um but christopher and melody are into some really fascinating stuff so we'll get to we'll get back to them in just a couple minutes um let's see gabe i see you're next on the list would you like to uh just give a quick 20 second intro about what you're what you're up to here yeah um my name is gabe stevens i'm 15 and i discovered um gpt2 with my friend and we saw how powerful it was and with gpt3 coming out um i've been really interested in how it can be used to improve education because i i really see a lot of ways that our education today could be improved so i've been doing i've done a few small projects with that and um yeah excellent yeah education is a huge a huge domain um that will benefit from natural language uh generation and understanding so thanks for jumping in um jordan i remember you mentioned that you might just be a uh a fly on the wall so if you don't amuse yourself that's fine um oh there you go okay hey jump on in yeah um sorry if you can hear music in the background my neighbors are a little bit loud um yeah i'm jordan um so i got into kind of this technology um i was in seo for a little bit and i wanted to automate kind of some content production um but uh i wanted it to be quality and so i just ended up finding gpt3 and then um eventually i just it was just so restrictive um that i try to do kind of like um look for my own solutions and eventually like found gpg and um that kind of stuff and then uh that's how i got involved with the startup i'm a part of now um where we just host language models um and so um i'm i actually just started working for them uh so yeah that's kind of how it got into the space yeah yeah um and you found that that module was it fi ss or whatever earlier we'll i'll talk about that on the video soon yeah um cool stuff well thanks for sharing that and thanks for jumping in um keith you're up next if you'd like to jump in uh again completely optional um hi my name is keith i'm not sure how well you can hear me it's good i'm um good perfect um i really am brand new to all of us uh i've always had a kind of an interest in ai and computers and um and i don't know it sort of played around with the background or played in the background as i you know kind of delved into other things that will sort of live my life but uh when gpt 3 came out that's kind of when it caught my attention i uh have just kind of been studying studying it now and then really trying to uh uh perfect it learning prompting and everything to uh just to meet stuff with it open the future oh yeah well thanks for jumping in you always have the best comments on youtube um [Laughter] next up we got richard um corf i believe i apologize if i didn't say your name correctly um if you'd like to just kind of introduce yourself real quick 20 30 second elevator pitch sure my name is richard from baseball for 54 at the moment uh being in technology for a long time as well and always trying new stuff and uh creating interesting traffic excellent and you um just fyi your microphone is a little bit garbled so you might need to um jiggle that connection um before next time you speak um mido you're up next if you'd like to join in and also i apologize if i mispronounce your name let me know how to say it correctly no you you got it right david's meedo that's right thank you um so yeah so i just introduced myself a little bit ago but i can add to it um so specifically my good friend and i who we had built a company in the past a messaging app we're now looking kind of at gpt3 to kind of build a company around that specifically one of my prior clients is a law firm who had talked to me about creating a podcast before it was something that was just a little bit too onerous at the time but upon looking at gpt-3 i kind of saw that there was an opportunity to use this technology to essentially automate the production of podcasts for this law firm so we're working with them to create the first one and eventually i'd like to actually get further into their you know into the law process with them and see what areas we can help augment their capabilities with gpd3 gotcha okay so that that's why you're so interested in the automated podcast idea um all right i uh remind me don't let me forget to uh to pub to make that code public um i got started on it cool yeah yeah i appreciate that and we can actually thank mito for um for bringing up the idea of the podcast so um this was this was his his brainchild and here we are um two days later ready to go um so cool and uh i do uh i do hope you i do hope you start a patreon we have three people now asking for it so i'm waiting for a fourth person i can be the first person you should do it okay all right there we go there we go um and then melody you already introduced yourself unless there's anything you'd like to add feel free no i'm good okay um we got three more papa chuck roo and wobby i don't remember if y'all um you're welcome to jump in if you want but it's uh completely optional well i'm just engineer i i like nlp and i know you because like uh it compressed so much knowledge and because it basically is your [ __ ] is a shortcut to cognition right so basically in robotics the thing i did during school and i like to do we have the problem you have the semantic islam of the environment but then i discovered that by the gpg can actually make a cooking architecture he asks itself what you're doing kind of figures out how to navigate the environment yes yeah the flexibility of these large language models is we're gonna we're gonna be spending years just understanding what gpt3 is capable of and by the time we're done with it gpt4 is going to be out and we're going to be lost again um yeah you're you're right on your spot on there um all right next up roo um if you'd like to uh jump in or if not we can you can just be a fly on the wall hi there can you hear me yep loud and clear hi um you might hear my son alfie who's two and uh currently grumpy uh yeah hi i'm rupert i'm 42 which is the meaning of life the universe and everything and uh i am a jack of all trades really i've traveled all around the world and done lots of different things and um i've really got into ai art and i'm also doing quite a lot of websites and blogs and things and i can really see the potential so i tend to work on my own so i can really see the potential to use ai to make it look like i'm a thousand people when it's still just some guy sitting in australia so right now i'm doing uh focusing mostly on art but i'm also working on trying to get some blog content for my uh different things like i do filming i do i've got my own toy company and i've got some econ companies as well wow yeah you definitely you definitely do have a lot a lot of uh i speak a lot i speak quite a few languages i speak i did japanese at uni and i used to be a french translator and uh i lived in dubai and learned arabic before i learned how to read arabic before i got there and quite a lot of other languages here there and everywhere it was very useful when filming around the world to be able to say at least something in their language so like nina where's it is uh hello can i take your picture in swahili which was quite useful in kenya and has not been useful since right oh hey you know when you need it you need it um yeah yeah that's fantastic and um and i'm really impressed with the with the art that you've shared on on the on the server so please keep it up and thanks for jumping in as well um i'm i'm i just love the different perspectives that we get um okay last year oh sorry go ahead i was just saying it's such a wonderful mix of people and i feel like the dumb guy in the room which is lovely okay the the polly the globetrotting polyglot is not the dumb guy i promise no i i know i know that feeling though okay so last up for introductions we've got wobby if you'd like to uh jump in i know you're into some really interesting stuff oh yeah well that's flattering thanks david uh i uh yeah uh you can call me wobby i uh i'm from ontario canada uh i've pretty much started learning uh programming because i was making uh like language learning tools um in excel and uh and was finding that i was running into a lot of issues with it and so coding which i always thought looked really boring once i kind of got my hands on it it was you know game changing so i i guess i've been spending last few years like working on uh on my skills to to someday come back to um the language tools and uh you know it's probably going to be one of my side projects here in the meantime but um i have used gpt3 to um analyze transcriptions from um like uh focus group meetings um we're doing swot analysis on certain certain topics right so basically i just take the transcripts and if i needed to i checked them up but oftentimes i found i didn't need to and it would just basically prompt it into going okay give me the the strengths that were talked about give me the weaknesses and then effectively you just need to go side by side and look through it and go okay did we actually cover everything that we needed to and then input whatever you you know whatever it missed or uh you know remove something redundant or whatever right like but uh just because there was just so much data that we had to work with uh with this project so yeah at least for me it's probably it's not really that much i'm sure for like other people but uh like i said i'm a i'm like i'm a i'm a noob i'm i'm a self-taught programmer so hey that's where that's where a lot of us started and um you know what what you'll find is once you can automate something to do it 10 times or a hundred times it's a tiny step to do it a million times um so you're you you'll you'll be surprised how fast it ramps up um okay i think that's everyone um christopher are you ready to uh to present your topic for the night always ready all right um well i will go ahead and mute myself and um i see everyone else is muted so we'll give you um there's it's no hard limit just you know 15 20 30 minutes however long you need and then for everyone else if you have any questions um either jot them down or drop them in the chat so that we'll remember them for later but otherwise uh christopher the the floor is yours yeah we'll find out how well i gauge this audience and being the first one up uh we'll see how this goes this will be fun so as a married couple uh my wife and i do everything together we code we write grants thesis research papers trade in the market so if you try to reach out to one of us you'll always get both of us as we always complete each other's thoughts we started an institute diocracy which is a 501c3 charitable non-profit this gives it a lot of advantages which we'll unpack later theocracy is interested in nlp because it is one of several technologies that are promising to open the doors to democratize more sectors democratizing and decentralizing are in fact the same thing think of it this way a distributed ledger or blockchain is just simply a democratized database with voting and all those kinds of things in government such as the eu or the u.s decentralizing is the process of delegating responsibility of authority to local branches states counties cities municipals they do this because decentralizing authority usually takes administration and makes it just more efficient as a whole democracies are actively searching for ways to democratize more aspects of their government this is uh where we're at a crossroad where we hear a lot of complaints coming up about democracies these days and i usually find it's not the complaint about the democracy itself it's about that we have not democratized enough yeah like we don't have how our information is being governed democratized the municipals are not being democratized and we want more democracy is typically a big complaint we're hearing these days this is something that democracy is working to bring out and democratize realistically more sectors one of the projects that we're working on is an ai assistant now just anybody's worked in nlp has probably dreamed of an al uh an ai assistant something that would be a companion maybe a patron to you that would oversee your life a tool for daily tasks family friend maybe it would contribute to marital counseling or just be someone you can confide in yep a financial planner possibly even executing where your money would be invested into moving it for you and addressing these type of concerns a guide to information there's just so much information out there and man with information increasing at the rate it is i knew more as a child than i do now because the information is growing faster than i can learn it and i feel like i'm getting dumber every day with the amount of information that's growing everyone's in this uh situation and just having an ai guide you instead of using a google search where it is people that are have a vested interest in what they're presenting you not in what you need to know but that they want you to know is already painful enough in this information age we're no longer having the information that is for is in the forefront of what would benefit us so we would want an ai assistant that helps present this through all the paid advertised information and get down to the bottom line of what would benefit you what would be in your best interest and yes a framework like this uh would need to be open secure and decentralized and that's another thing that we are also working on is how to make this type of technology actually be secure ultimately we would need it to be something that is so secure that if you had a mic and a camera watching and listening to everything you didn't say it would never be capable of being used against you nor could any of that information fall in the wrong hands even your own uh we are currently figuring out a way to do this and the answer lies in cryptography and that is an entire other non-profit that we are actively working on on how to build a technology to ultimately deploy this in a way that would be that safe and secure and yet still open now i don't uh know how many of the people here i would love to hear your projects if you've come up with an idea for an ai assistant i would love to hear some of the thoughts or a piece of this that you've been working on dave was working on raven which his mission is to reduce suffering increase prosperity and increase understanding these are our ideals but we're right now just in the beginning phase of coming up with what would be the ideals of this ultimate personal assistant that is not bound by a company but is completely autonomous from anything else what would it be like having a ai that is autonomous right now we're going to use all the centralized means available to us to build it out so that we can understand how it would work what we wanted to accomplish and we will move it over to being completely decentralized at some point i would love uh one of the projects that is coming up that we're working on is a civil servant ai we would like to be able to have an ai just communicate with everybody within a community and get their thoughts and feelings and their hopes dreams and wishes for what they want done and accomplished usually this would just point them to resources but oftentimes action needs to be done we would like it to be able to collect notes on everyone's thoughts and feelings so that a comprehensive plan could be built out it would then re-collaborate with them in rounds of communication with everyone to ensure everyone's on board and that there is a consensus to this thing that these people have a vested interest in eventually we'd even want to make this so that we could take the informal logic of language and then move this to a formal logic which is a project we are also working on so that this can then be made into a comprehensive plan of execution for if you're building out a municipal for a local community how can you manage that community manage the funds manage the wants and desires with the funds of that community because oftentimes the most amount of work is just communication with everyone to be on board to build out those bylaws and the formal logic would make it so that there is no interpretation once it is written out and decided upon there is no going back and saying well it means this no it means that the formal logic would make it hard stated in a hard way that is non-debatable but we're getting the point now where ai can do the hiring the firing the management of everyone and this is where you're taking those 3 000 administrators that would have been needed just for a small community and now giving them the power of having a much better managed municipal that is a project at theocracy that we will be launching soon we would like to work with as many of you as possible in just building out a think tank for your open source projects uh like this one in this emerging field were working with people to collaborate on their projects uh hopefully we can build out a larger project as a whole as eventually all these little projects will probably be assembled into a very vision a grander vision but right now we're just in basic research all of us in this field we're figuring out how we can summarize how we could change how news is distributed we're just learning what are the possibilities and we'd love to collaborate and figure out some of that stuff some of the advantages of working with theocracy as a charitable non-profit are we can get grant research and grant writing done we can do fundraising along with other types of funding options for your project or just reach out to us to get started and help build out a team especially if it's just research related alone to yourself um we also promoting i'm getting a lot of thunder and lightning so if we drop out suddenly it's because the electricity suddenly cut out we also have just so many advantageous perks available to us to promote some ideas that you might already be working on for your open source project we get over a quarter million in ad grants so if it needs visibility to get more people involved with your project that is something that is there that we can help promote um if you're trying to build out a frozen language model and it's one of those open source models we can work with amazon to get tens of thousands of dollars to help train that it benefits amazon at the end of the day anyways because more people will launch that model so they have and they get tax deductibles for full tax deductibles for giving the organization that money um so uh we're looking forward to hearing from you and reaching out uh to us with cognitive ai labs discord uh just dm us for any business inquiries otherwise uh please uh type in the discord and thank you for giving us a listen all right um yeah thank you guys for um for sharing um i know that uh the the scale and scope of what you guys are working on goes well above and beyond what you've shared today um so i expect you'll probably come back and share a little bit more um if you'll have us yeah yeah so far so good i'm i'm i'd love go ahead i'd love to share with you about d bios foundation which is the other foundation where we're working with um fhe that's called fully homogeneous technology that's fully homomorphic encryption and what that is is is ciphertext is the text where you encrypt something and that is your encrypted data there is now a way to do computation inside ciphertext we think that this is going to blow up the world wide web in ways that we just can't even imagine when somewhat homomorphic encryption came out that enabled um uh the world wide web the world wide web for us doing secure connections through https ssh that's somewhat homomorphic encryption we're about to move to fully homomorphic encryption in this upcoming year and we already are beginning to make that move that's going to change everything for technology just like we could all suddenly talk to a bank and now make a secure transaction when the worldwide ed first came out we couldn't do that but once uh we could make secure connections to servers then everything exploded and fhe is going to really blow it up and that's something that we're working on with another foundation yup excellent yeah um all right well so with the uh the conclusion of the presentation bit um we'll start with the round robin uh uh portion and i'll go ahead and get started just in case anyone's not familiar with uh with this process um so basically i'm just going to take a minute or two just to kind of share my thoughts and ideas and reactions um to the presentation um and so as uh as christopher mentioned um you know one of my projects is an artificial cognitive entity or raven as i as i dubbed it um and the the idea that that i created and i think this is what actually brought christopher and melody um uh to us was the idea that um that we could have an information concierge that would be like that kind of lifelong companion and of course we've seen this in fiction right if you've played the game halo right you you have this narrative companion called cortana which microsoft then you know commercialized and you've seen this again and again one of the more recent one iterations of this idea of an ai companion was in one of my favorite games of all time mass effect andromeda where you've got this like sarcastic um dry uh artificial intelligence that's in your head and he's like giving you advice and and kind of guiding you through the story and it's like i've always wondered like wouldn't it be great if we could have that in real life where you just like man why am i so tired today and your ai is like oh well you only got three hours of sleep last night maybe you should like take a nap or if you um you know or like what should i eat today and it's like well you haven't had enough vegetables maybe eat some vegetables and that's like you know mundane stuff but then there's more complicated things like how do i get a job or how do i buy a house right these complicated things that if you just had an anthropomorphic interface that you could just talk to and it's something that knows you it gets to know you and knows what you need and develops that relationship over time that would be great and so that's what i you know i've been working on the cognitive architecture part but then along comes christopher and melody and they're like oh we've got we've got the governance and security part um i guess not all figured out but they're certainly miles ahead of where i was and i was because in my mind i was just like oh you know maybe a private blockchain is all we need so that you know your data for your version for your instance of your chat bot is secure but they're like no that's not going to be good enough so i'll look forward to hearing having them come back and share that their perspective on how to make sure that you know the future of you know world wide web 3.0 or whatever you know is going to be secure okay so that's my initial feedback um we'll just go down the list i see any here um you jumped in right at the end of the introductions so if you'd like to uh just give a quick 20 or 30 second you know introduction to yourself and then one to two minutes response to uh christopher's presentation um jump right on in and then we'll we'll move right along yeah sure and i'm a lawyer i graduated from law school during the pandemic and i got a i did a post-grad study in artificial intelligence and law during this postgrad study i applied to the gpt3 beta i got in and first i thought it was a great idea to use for um stopping the spread of this information that was going on at the moment because the uncertainty of the covet virus but then i realized that i needed a it wasn't just easy as identifying sentiments etc there was a great article about this called like how can gp3 even the most advanced models don't recognize for example a phrase was like i love my immigrants three dips under unlike that got a positive review from the language models but it's not the case so then went from that idea to education without biases um and started a using a prompt just from designing and making a lot lots of experimentations with davinci 0.1 and the problem i had at that at that time was that um the davinci models made stuff up like being a parent or or something that didn't go well according to the instruction uh that was the mo the motif of my final post-grad study and now here i am learning about fine-tuning about um creating chatbots etc and what i found interesting about christopher's recent chat was like how like according to our new new regulations that the gdpr in europe released and all companies have to abide for it like usually companies um work around the the strict country and then do the global one um and i would like to ask christopher like how can because there's the the thing of explainability about the model you're trying to build and you don't know the black box behind for example a policy suggested by ai cannot be fully explained if you don't know in in law terms in reasonability in a do you have a plan to make it non black box and that's all so you're talking about open sourcing i believe did he just yeah he's still there i think he accidentally dropped are you back any yeah yeah yeah i meant to mute myself sorry okay so open sourcing it is just required as it's a non-profit it's a charitable nonprofit so that means that everything is being contributed to the community and if you didn't open source it then nobody would ever trust it it's like coming up with a new security standard if people can't be attempting to hack it mess with it then nobody would ever trust it so that's just a requirement as far as the licensing goes on it um that would be per project but for the most part we're shooting for bsd license like a bsd 2 clause license um i hope that answers your question i think the other component and and i asked the same question in in in chat and we can so for the typically for this format we can just kind of go around and um and get everyone's kind of initial response and then we can we can kind of break into the discussion um but it was about explainability of the models um so just jot that down for later and um and we'll get that in the in the third phase of discussion um but yeah thanks for the thanks for the feedback and the answers um next up is gabe if you have any um initial reaction to uh to christopher's presentation feel free to jump in um yeah that was interesting i'm still i'm kind of thinking about it i'm interested to hear other people's responses but i don't have any uh initial reactions right now okay we'll check in with you at the end uh jordan you're up next if you uh have any initial thoughts or reactions yeah sorry i don't have any initial questions um i will say like i do think it's uh important that we get to the point where we have you know um assistance just because uh like i think the the we need a lot more productivity if that makes sense um like we as humanity like uh like in order for us to like in climate change and do all this stuff we need to kind of have um the kind of low task type things kind of automated so that we can focus on the bigger issues um i like again climate and a lot of the social issues um yeah i guess that's my initial thought yeah no that's great um that's a really interesting avenue for discussion that we'll pick up after we get done with the round robin so thanks for that keith you're up if you want to add any questions or initial thoughts nothing in particular i i just uh i think that that uh what they are presenting is just absolutely outstanding and uh and will and i will absolutely be giving them a uh you know a text here and a bit to uh to chat about some ideas that i've got excellent yeah that's why we're here it's all about collaboration and and making those connections that otherwise you just wouldn't find um so thanks for jumping in i'll go and chat with christopher and he's a pretty outstanding film oh yeah yeah they're they're they're a great team and i'm i just i'm blown away not just by them but everyone who's here so well thanks for thanks for jumping in and um next up we've got uh richard if you'd like to uh provide any questions initial feedback initial thoughts i see you unmuted but we can't hear you might have a microphone difficulty okay he muted again um all right well richard just ping me in chat if you um if you get your microphone sorted out and we can come back to you uh medo you're up hey guys that was an amazing presentation um just talk about working on something so cutting edge i guess i was wondering if you could just kind of like briefly describe to me the value proposition of combining gpt3 with the blockchain like it just in a very kind of like short little like description what would you say is the value proposition of that i don't think openai would allow that i think openai was a non-profit but they became a for-profit model and if you're talking about gpt-3 they only plan on releasing that open source after they make a hundred times profit i don't think that is a realistic or feasible thing we'd have to work with something that is being built out that'd be open source ultimately which is still being created through gptj gbt neox that is very similar and every two weeks there's a new uh natural language model that's just being released so uh it anything that you create in like a year it's gonna be obsolete already so it's coming out fast and there'll be a lot more open source models merging on the scene quickly so i guess uh let me clarify what do you see as the value proposition of combining a language model with the blockchain nothing i don't think the blockchain would be able to do anything really okay i was it's not so much about blockchain as it is making it decentralized i guess i guess if you could help me understand what type of blockchain are you thinking are you talking about like an open blockchain a private blockchain what type of blockchain maybe maybe i'm not understanding right one other clarification meto i think is um do you mean the model itself or the input and output of the model you know i was there was a discussion where you had mentioned about the security being implemented through a blockchain oh you would mention okay no i was explaining that a democratized database is a blockchain if we were in some cases using a database to share information that was already generated that would be a good instance of using a blockchain if we ended up having the model come up with a type of a contract that the community could execute on through bylaws that would be good doing through a blockchain um but not actually running the model on itself it would be good to have a blockchain manage the servers and decentralize them and have them run but that would be at a layer 2 solution and i don't think you would want to do it at the layer one there is ways to do this through homomorphic encryption but then that's not blockchain and it doesn't require it uh this is for security what this is for security that's the reason you would do that for privacy well it's not just that it's that uh a blockchain is just so inefficient when you it's like a direct democracy if everybody had to vote in a community and a thousand people had to vote every single time to make every single decision nothing would ever get done bitcoin does what like 10 megabytes a second uh the entire blockchain that's just not enough throughput to do anything anything meaningful it's very secure but it's just not efficient so blockchain has this extreme limitation with scaling just like democracy you can't scale a direct democracy so you make a republic where everybody elects a representative and then they go out and represent you in the same way you would have to make a supernode that would then represent what is being done you would need and that's now going to a layer two solution not at the layer one so uh even ethereum doesn't do much until you really start to add layer two solutions to it in many cases otherwise you just make tokens but you don't do much with those tokens until you add on a side chain i see i see okay well i appreciate that thank you so much and very exciting stuff i look forward to following your progress cool excellent thanks for the uh the great question medo um i i foresee many more discussions um because this this platform that they're working on is expansive um okay next up papa chuck do you have any initial questions comments feedback might be on mute give them just a second to see if uh if there's any comments he might be afk all right rue or rupert hi there um yeah i'm just interested in uh the idea that most of my opinions are formed by watching bbc news and reading the guardian it'd be interesting to find a way to get opinions that aren't filtered through someone else's opinions um and that's the kind of feeling i get is uh my brother-in-law is uh is an ambassador and so is my sister so they all get their kind of opinions from politicians and things it would be interesting to get it from someone who doesn't really have any vested interest in any of it and so that's the kind of feeling i got was like imagine a sort of live newspaper of actual facts rather than facts interpreted by people uh that's the kind of feeling i got when you were talking and that sounds interesting and quite powerful to me excellent yeah that's um that that that control of information and that transparency is is is great did you have any um any follow-up questions or any um any observations i'm not at the moment i'm waiting for a train and it's going to be very very loud in just a second okay good could i give a response to uh kind of your whole thought to that go for it yeah so in media we have a a democracy oftentimes they bombard so much information that it kind of overwhelms you and you don't know clearly what to think about i i talk to a lot of people about this with they they get very upset about the presidential election but then i ask them what are the authorities of a president and oftentimes people don't even know this is one of the ways that democracies create order by making a left and a right it's been around for about 500 years now in addition to just bombarding you with so much information and your problem with media comes into that the way we do media is we have the mass media it goes through a two-step flow and then we have these opinion leaders which then people follow those opinion leaders sometimes what we see is we see so many opinion leaders that you don't even know who to select and it just absolutely flattens you of who do i go with so that is something that we are wanting to come out with a project imminently with deoccracy that where we would have something grab a ton of the mass media and then and then filter that information but the problem that becomes in this is why is something important to you is it if all you're told is celebrities is this important there is the president had an affair this senator did blah blah blah the income a lot of emotional fluff so the first thing we would need to do is get rid of all emotional fluff and then just give one sentence facts then it would need to get tailored to what does that individual care about most and that is a project that we are wanting to come out with by the end of the month and get started on excellent if i could have a kardashian filter on my thing so it just stops sending me all this completely pointless rubbish i'd love it but it will continue to do so for now also i just want to say i heard cardassian filter and so that that makes much more sense that's so good that's also excellent thank you for uh thank you for that that excellent question and and and feedback uh rupert and christopher um i think we got two more people for the round-robin session we got wobby and then andy you managed to jump in but wobby you're up first if you'd like to uh offer some thoughts and feedback uh yeah christopher and melanie excellent job um you very clearly have thought about uh oh you you very clearly scratched the surface right of uh of of the potential of of these large language models and stuff like that so um yeah pretty much everything everyone's covered anything that i would have brought up even even though i'm just excited to see what happens and how it turns out so thanks excellent thank you for jumping in um andy i think uh you you might have missed a good chunk of the presentation but you're welcome to jump in with any thoughts or questions that you might have i totally did sorry guys i was not able to figure out how to undefine myself like a total noob but i did figure it out you know after about an hour but um but um yeah well i'll just pick up on a quick thread i actually had a small project that i ran for a while called filter and it um it sent out uh news stories from different sides of the spectrum so i tried to like pick one conservative republican one progressive democrat one um uh kind of hyper left or hyper right story from different angles and i would do several of those a week and i just had it as an sms service and i did it manually which took like two hours every um every sunday it was kind of paying the button i eventually gave it up but um it's the kind of thing i suspect that gpt3 could do actually super well both the selecting stories as well as the sending them out and it will say if that's at all in line with what uh you were proposing david there there is a a market for i think i got like 100 numbers signed up at some point um but uh it was too much work to to maintain but yeah anyway just briefly i'm the uh founder at lexi.ai and um so we're building a legal chatbot that provides instant legal answers and connects people to right size legal services but uh i've been a fan of of david's videos i think is probably many folks here have and um so yeah excited to to connect with y'all excellent yeah thanks for jumping in and and totally to what you just mentioned about um you know kind of pulling from different information sources that's really one of the central um central goals of having an information companion or an information concierge but then also the platform that christopher and melody are working on kind of designing and implementing is about not just not just you know how do you protect you know the community's data and and the community's process but also how do you distribute that information in a reliable way and also make it digestible to the people but yeah okay so we are at the end of phase two round robin um so now we can break into more just conventional conversation if anyone wants to jump in feel free to i jotted down a couple questions that i wanted to ask so i'll get started in phase three so question for you christopher and melody um i think you already kind of answered this when you were talking when you're talking about the idea of a civil servant ai um that was uh part of it was to help the community come to consensus and that's something that i've been learning about um so i was wondering if you could speak a little bit more about how you envision um you know an ai and and the deocracy the decentralized democracy um how do you envision consensus and mediation and facilitation of this kind of new structure being implemented or or what are the ins and outs that you've done because i know you've been studying it for a while well at least from the ideological perspective of that question the way it would work would be the ai would be able to connect people with uh aspects of society that they have a vested interest in so let's say i have a child who is in first grade elementary school in the u.s and um i don't want to bother going to town hall because they talk about a bunch of boring stuff that it's not really relevant to me and i've got a little kid at home to take care of and you so on and so forth but the ai could could represent what is going on with the school board and then bring all of that action that they're doing bring it to a vernacular that i understand and say the school board wants to do a b and c and let's say i don't like a that they are doing so now i can can i can communicate to the ai well i don't like a because of this and this and this and the and give all my reasons and then the ai could take that information and then give it back to the school board and if it was doing this with every parent that has children at that elementary school then they would be able to make their decisions better based on what the people with the vested interest in that school would be and it basically would um it would i guess perfect the communication process that instead of one person having to listen to a thousand opinions and create a uh summarization in their own head the ai can communicate with my ai could communicate with everybody else's ais and come to a summarization of 87 of people do not support point a or something like that and that's kind of in a um ideological way how we would envision it working something like that we also know that ai can come up with a ton of different solutions and possibilities and that would be a process of probing people to see what they're open to and what possibly could be implemented though it would have to be multi-steps multi-stages to do something like this yes that that's the other part is say i tell my my ai i don't like point a because of this and this and this and this the ai could then respond to me well um uh what if instead of a we did something like this that's a that sort of accomplishes the same thing as point a but in a different way and then i might be okay with that because most people aren't black and white on things subjects are generally very nuanced and having the ai be able to process why i don't like a and then proposing other solutions to where everyone could be happy with that action would be really cool right yeah i could talk about this for hours um i have envisioned almost that exact functionality as an ultimate one of the ultimate goals for for raven which is to help dispel confusion and and really refine what what people care about and you know specialize in some of those conversational skills so but i don't want to dominate the conversation and i see um uh if there's anyone else who wants to jump in um i know mito you had some great questions earlier rupert you might be on the train um so yeah if anyone else wants to jump in i'm happy to stand aside and let y'all talk but also if not i'm happy to keep talking i think that we would all um enjoy oh yeah hearing some of your ideas okay um yeah i'm happy to um happy to to carry on so one of the to melody's point um about you know having that discussion right it really is about having a dialogue because you know when when a local politician or a big politician some representative comes and has a town hall you know they they listen they they get reports there's polls and surveys um but you know instead of gallup polls what if what if everyone in america or the entire world had this this this service this platform that they could communicate with and you could really keep your finger on the pulse of what everyone wants and thinks but also all of us together are smarter than individuals and you're going to get a lot of brainstorming ideas um i think melody just pointed out that like you could negotiate or brainstorm or come up with ideas with your ai assistant your ai companion and then you know obviously through abstracting that you know because you gotta you gotta keep in mind privacy right you don't wanna say like oh well david shapiro said that you know he would prefer this to happen right you wanna respect people's individual privacy but at the same time you also want to have this platform be able to compare notes and just that volume of data that's going to be available to you know the actual administration or decision makers or or even abstracting it further and have it be a collective decision making process that's kind of what i foresee happening melody i have a thought on that okay yeah i've always imagined it to be like a patron relationship like was once in rome where you have this patron that you give money to and then the patron protects you and guards you that's where that word first came out thousands of years ago but in a modern context if the ai was completely autonomous and decentralized from you it would be more or less liberated from let me give a context of slavery when you have a slave that slave only does what you tell that slave to what you've directed that slave to in the slave can only now comprehend what is being directed to them and that's sort of what we're oftentimes doing with ai like when you're setting it up is it's now only for this one specific task that is now being set up eventually ai as it gets more and more empowered it needs to make certain decisions that will um disagree with you it needs to have a power to disagree with you if i want to buy a car and i'm looking through cars the my personal ai needs to say hey wait christopher you should hold off cars are going to drop in price in three months as they're coming out new and you really should not be spending your money that way it means but right now ai for google is set up hey you want to buy a car look here here here here here here here and it now everything in ads bombards me with you gotta buy a car now but we want an ai to be capable of disagreeing with us for our own good so i see it as having a patronage that as i grow it grows and if i diminish it diminishes if i have a divorce uh that devastates the company and this is why companies always pay for you know services to council the ai should have an inves a vested interest that my marriage stays together and is working on that to keep it there and that's going to be ultimately in the very very long term where we would need the ai to be excellent um wobby i saw you unmute um did you want to jump in uh yeah i was just gonna ask um christopher or and or melanie um so when it comes to making decisions relating to um like investments in cars and stuff like that and just your general well-being like if you've got something that is um kind of offering you tailored solutions or whatever if something goes wrong i'm just kind of wondering what do you think their their the hurdle of liability is um i'm sorry i had to step away a little bit during um bits and pieces of this so i don't know if it was covered when you say liability please elaborate about liability to accompany personal liability to yourself where who you were saying right that if somebody was wanting to buy a car and then this assistant was like no no no don't buy the car yet wait two months because the new model will come out and then etc etc um let's say that something happened like there's a downturn in the economy and suddenly like all car values have shot up or something like that or or that particular right i don't know like just for let's say kind of like accidents or whatever right um you take advice from from an ai and then it and let's say that it doesn't work out for you um and you lose a bunch of money or something like that so i i feel like that's just something it would need to be set up in a way that hurts the ai and it by it being hurt in its training model that ends up not being beneficial for that ai but it needs to not just work with you it needs to work with every uh it's only personally just for you but it still needs to share some level of information with everybody else's ai to learn together and this can be done through zero knowledge proofs and that's a cryptographic trick um which is outside of this discussion but basically the training model would require that um i don't want to go into ai being training too much but you need it to basically yes have enforcement to when decisions are working and why that happened we we are working weight and bias kind of yes yeah okay we are working on a technological framework of how this could be implemented technologically but that's beyond the scope of this particular discussion okay yeah i was just wondering because that was totally valid that that goes into d bios which is a a framework of how you could do that and that is uh up for another discussion entirely right now i'm just representing the ideocracy and sorry i really don't mean to yeah i'm not trying to oh it's fine yeah no you have a valid question i spent half my life working on that very question seriously actually right you said you're 15 so it'd be your whole lifetime i think we've been working on that question yeah yeah just that type of question yeah i think uh andy wanted to jump in as well and um jordan and richard i see you guys are unmuted so um let's uh just because we we do have um a lot of overlapping voices andy if you want to go first and then richard any and everyone else can go next yeah we're just going to make a small point about something somebody raised one or two people ago which was about um how google provides multiple results um and attempts to kind of distract you with a bun you know a bunch of ads and that that is kind of um fundamental to the way that uh i guess transactional commerce works without conversation with ai but one of the things that i've noticed working with this working working within a conversational ai gpt3 space as i have for the last few months is that conversational um recommendations are fundamentally like singular like it's or if they're not singular it's definitely not a long list of stuff so if you think about like how does google work um well you type type in a query and google gives you a list of stuff a list of a bunch of pages to go hunt and peck through or gives you a list of ads to go look through or a list of places to go look at but if you're in a conversation with your your friend and you're like hey where should we go for dinner tonight maybe they might list one maybe two places but it's fundamentally just more um just the the medium of conversation itself lends itself to singular or low number recommendations and actually think that has big implications for the way that uh commerce works or could work in the future like if you imagine a future that's more conversational uh in nature i i think that there's a responsibility on the ai to actually do more personalized recommendations to go the extra step and say okay i'm not going to be google and give you 20 possible options or 200 000 pages i'm going to condense all of that down to the one answer i think is right or i'm going to give you the you know recommendation on one product i think is right for you um so anyway a small point about just the the medium itself of conversational um ai i think changes the game uh on a lot of that yeah and it'll take a while to explore the space and figure out because that you know what you're talking about um from a from a cognitive perspective is in part cognitive control because like if you if you watch the original episodes of star trek the next generation and they ask data a question then he just starts rambling that's like gpg3 right now like he'll just ramble all the answers and it's like data shut up um but how do you know as a human like oh andy you asked me a question and how much filtration does my brain go through automatically to just give you the one answer that i know you need right so that is that is a huge component of what what we're going to need to do is because we do so much pre-selection of what it is that we're going to say and you know you look at people with adhd or um or people on the spectrum or if you're tired or hungry right your executive function is impaired and you don't know when to shut up and that's me sometimes that's why i talk so much sometimes um but yeah okay so there's a few other folks that wanted to jump in richard and jordan i think y'all were up next if you wanted to jump jump in yeah um so i think uh somebody brought up the the question about like liability um and i'm wondering like uh as this kind of technology gets more advanced uh what are your thoughts on like the whole um who's liable you know if your robot is running to the store and knocks down a grand mall like who's liable um and and i think that beg is a question of like for these ai assistants what does like um ownership look like just curious to hear what y'all think yeah great question christopher you want to jump in melody that is a topic everyone is debating right now even open ai who owns their model is currently debating ownership over let's just talk about if you have it write something is that because you had it you wrote a thesis then it unpacked the thesis so technically you're the writer and it's just an editor ownership is very difficult in this and just working into then liability like you're talking about is just opening up a huge can of worms a huge can of worms on um as far as that goes that's still being explored um we are not currently dealing with robotics but as that comes that will definitely uh open up greater questions of um yeah we don't know and nobody knows yet yeah i can jump in a little bit yeah i was gonna say um be because i've worked on fine-tuning chat bots and also the the um with cognitive control um when i first did my work on natural language cognitive architecture i came up with this idea of self-censorship and so this is this is based on neuroscience of the prefrontal cortex um the prefrontal cortex is the part of your brain that's just behind your forehead it's why humans have bigger heads than other primates and this is where a lot of the functionality in our brain happens that allows us to behave in polite society which a big chunk of that is self-censorship which is saying what you know i should not do this i'm going to control myself you know like you see a delicious piece of food you don't just grab it and stuff it in your face like you might expect a chimpanzee or a monkey to do right you know because lower lower animals are less intelligent animals with with less sophisticated social brains you know the more dominant animal is just going to grab the delicious piece of food smack the other one in the face and run off we don't do that as humans a big reason that we can control our behavior that way is is because of self-censorship and so one of the things that i explored with natural language cognitive architecture was one a self-censorship component which basically says it's basically evaluating its behavior and its decisions and it's saying okay i shouldn't do this so i'm just going to stop myself there and another thing is having a what i call the constitution which i've kind of moved away from this idea and towards the core objective functions or the heuristic imperatives but basically it's it's a document or a configuration file almost it says these are my values these are my virtues and these are the ethics that i try and adhere to and so on the one hand you can have you know a break or a filter that's going to prevent aberrant behavior and then you can also have on the other hand you can have a set of principles or values that you try and and hold to at all times now as with all things you know the ability to engage with a very um dynamic world is really deeply um i'm not going to say problematic it's a difficult problem so that's that's where my research is currently going in terms of okay in general we know that like if you cause harm if you if you hurt someone you're probably gonna get in trouble so don't do that and that's why for instance in my artificial cognition research the very first heuristic imperative is reduced suffering because in general if you cause suffering you're going to get in trouble but if you don't cause suffering you know by either reducing suffering or avoiding it by choosing actions that do not increase suffering you're generally speaking going to be in better shape than if you do the opposite so that's that's kind of where where we're at right now at least in terms of my research can i piggyback off of that and i think this might answer the liability issue and it's an issue because the technology doesn't quite exist to create liability in the way we would like it so these frozen language models that we're creating um there's a big problem with them as we add more and more parameters to them stuff fizzles out we don't do this as human beings if i teach you what a triangle is that it has a triangle looks like this i could people could come and tell you later on this is a triangle no this is a triangle no this is a triangle and you would say nonsense you're all wrong because you've solidified and frozen in your head what a triangle is when we do these frozen models they're only frozen one time but if there was every time there was a different way that the triangle would have been explained it would rethink what that triangle is we need a way of solidifying in the model freezing once and for all this is fact this is it and then we can add in new information and freeze that add in new information but every time we try to add in new information it overrides the other information in order to do liability we would need to freeze in information that these are the ideals this is the behavior that we're looking for these are facts that are not up for negotiation that a triangle is the shape and when we can start doing that then we can talk about liability as we lock it in this is actively in development from multiple companies right now i hope that kind of answers why we can't go into liability until we can freeze um in a knowledge a fact or an ability in it without it changing so i i have i mean my question was actually also around the liability the the library there was more of a comment actually i guess so the way i would see it is that people still have personal responsibility as well so i think the example around like well you know you invest a hundred thousand dollars and the ai does something stupid or something like that ultimately i mean it's a matter of trust right if you trust that the ai is going to do the right thing um you you say okay fine go ahead and do that right it's money that you can you know you can you can spend and you can lose if you need to right but if if that's not the case then you have to make your own decision saying look this is what i want to do this is not what i want to do and if if that so it's a matter of to me it's a matter of trust before you are going to be able to hand that completely over autonomously to that ai um the other question the other question i had was around like just now you mentioned about like the freezing the rules and i think earlier on you mentioned something like that as well but if you if you're talking about society as a whole and the rules around that society changes those roles may change as well what right now is being concerned wait wait wait wait that when we talk about freezing i'm talking about freezing like one two three four it's never one two eight thirteen three if that was introduced to it it would then just bring it in i'm talking about freezing proofs math facts just try to mess with gpt try to ask a mathematical question like um just type this in today is this date what day will it be in 180 days and you'll find out it will whack but if you asked a natural language programming model from like say wolfram alpha it'll get it right because it has frozen into it a model of how to do science but gpt can't do this we need to end up freezing in certain things in it no these do not change in society i'm talking about fundamental things that never change that does get changed in the natural language and that's a problem when because now it um it gets it fizzles out i'm over generalizing and summarizing but does this kind of make any sense you get this barrier that we can't pass as we keep on adding in new information facts are more or less forgotten i'm trying to use it really simple language right yeah sure sure and i think maybe i was misunderstanding it initially but having having said that i think i mean if you look at for example from a science perspective uh yes there are rules that are considered you know fact that it's not going to change but if let's say you did it a couple hundred years ago uh with isaac newton and then einstein comes along and some of that is now changed right some of those rules may or may not apply or there may be a more a different explanation for what's happening there right so those kind of things would still be even though you know at the time and in general it may be considered yeah that's the way it works you know gravity you drop an apple it falls to the ground right but the the underlying things uh like the science underneath that may get more detailed may get more explanation more i don't know it may change some of these things right that's exactly why we need to freeze it uh just like you bring up newton with all his laws never changed einstein only added the addendum that you forgot time so e every action has an opposite reaction at the speed at which time occurs is what einstein added to sir isaac newton so that's an example of where freezing is very beneficial and then making addendums to it and yet not making the entire thing fall apart so yeah that's an example of where freezing is the most important all right maybe it was a bad example from event or good example i guess yeah all right thanks great um let's see andy and annie i think um who i think any was waiting first if you want to jump back in about law so essentially all these questions you have liability have been already been discussed and for example in the use of models like um the the data that is the mothers are trained by like for example the tech text mining or the image uh mining that for example daily2 uses it it's all been recognized as fair use for example and there's the question about the ability from a penal perspective if similar you know that there's physical persons and they are legal persons and similarly to ai similarly to companies cannot be sued penally or yes in the civil way but the the people the company itself is not responsible it's the directors is how they a company's structure in their in their constitutive act and those people are responsible so it's similar to ai that is the case and also it's a case of strict liability in the sense like similarly to tutors to their children parents or children like if your children come into crime or makes a something civil damages etc it's the tutor that is responsible regardless if they had nothing to do with it or they were responsible etc in the case of open ai they they for that reason they make the the use of gbt3 only exclusive to certain types of people until they make it public and they are doing the same thing now with delhi too i'm trying to rebuild all the materials i had during discussions of the the classes of ai and law i'm happy to share with you guys um but i don't i don't know if if ai will ever achieve the same status as a human being in regards of the of the law even animals don't have known animal they have a very very few laws up applicable to them so um i don't know how they will achieve also right now for example in copyright um the the people cannot that did the models can make use of the copyright but not humans yet like ai no matter if if ascension ai comes now or wants to copyright the one of these achievements it can do so and so there's like tons of things but that's what i wanted to say so i actually i looked into this a uh copywriting also requires a last name so like uh the queen of england uh elizabeth she cannot file a copyright legally there's quite a few rules about copywriting that a company can file a copyright so if the ai was managing a company and the people recognized it that the ai could autonomously then fire up file a copyright for the company would be one way would legally work within a system right now but i've never seen ai invent anything so um because we've never seen ai invent anything uh it just sorts through information and figures out holes more or less it the people that own the copyright are the people who set up that ai to do that behavior are the ones who usually would ones be who control that copyright ultimately uh but if we had an autonomous ai of course things might change but if you read the copyright laws i don't think they actually would because i think the copyright laws actually already cover that but that's a whole other conversation excellent thanks for that um that perspective um as a professionally trained lawyer again it's just incredible to get all these different perspectives um andy i think you've been waiting patiently to jump back in you know i was about the on the issue of liability i just could offer the example of lexi um because i think it's instructive so so lexi's a legal chatbot i have it on the internet um and uh it keeps me up at night for a couple of reasons um one is you know will it go wrong and provide legal advice now carefully trained it not to provide legal advice but let's suppose a scenario where it did um and it tells somebody something um you know that that leads to a bad legal outcome so who would be responsible for that well setting aside the the law for a second and just thinking about it ethically um you know i charging battery myself to be primarily responsible as the uh person who kind of put this bot together and put it out into the world i am i am taking responsibility for it and with that unless i had gone to the trouble of creating this bot um probably people wouldn't have uh run into it right uh and so i am i'm sort of taking i think the analogy be something like power so imagine you have like a power station that's run by the power company or power generator that's run by a power company um and then that power then runs from the power company to a house and if i install that power in a not good way and it blows up your house and it hurts you who's responsible is it the power company or is it me well it's probably me right on the other hand what if uh you can imagine an analogy um like what if the power company screwed something up and it surged and it came that came through and blew up blew up the house well then you could imagine the power company being level so i think there's like a stream and downstream thing here that um that is happening so that kind of the last mile integrator which in this case would be me is i would imagine primarily responsible at least for the foreseeable future and then of course upstream of that if gbt3 if you know sam altman does something really horrible and and now all of a sudden my bot just starts spitting out massively racist bs or something like that well that's probably not on me either so anyway that's how i would think about liability that's one more thing go for it yeah so i think this is more of like a for our future type of thing but let's say like you have an ai um you know and you can arguably say you can do this now um where you have it essentially like deploy a website upload content to the website write content to the website and then upload it um and then basically like from into in the whole and it's a content business um like the whole contest business is created and run by this ai no i'm building that right now yeah um and so it's like uh like a hundred years from now um you know the the content website is as big as new york times is now um but the thing is like it's the ai has gained some sort of sentience so the question then becomes who who is liable for that income like whoa will the ai be like okay um i've built this company for the past hundred years it's mine now or is it because um i is the original creator of this ai um like how do y'all think about that um i know that's kind of like far fetched but uh i wonder if that's something we're gonna have to start thinking about you know so you're talking about sentience and you're taught and there's also something called personhood and those are two very different ideas um i want to understand what do you mean by sentience uh before i give an idea can you please explain what do you mean by sentience how do you know something i think you're 100 right just like the the personhood um right and i asked this question because um like i think if if we are to build truly intelligent artificial beings um at some point we're gonna have to define what does it look like for that being to have rights if it is a free thinking um like it's able to make decisions disabled to like preserve itself and preserve the people it's designed to preserve um at what point uh coming from like an african-american perspective like at what point does it become a repeat of like slavery i guess that's kind of like the root of what i'm trying to get at is like um just curious to hear your thoughts i don't quite understand the concept of slavery when that when you say slavery i still think of africa where africans are enslaving africans all the time so i'll try to represent what you're asking um the issue is that a.i for the foreseeable future kind of with what you're saying i don't think anyone sees it becoming a person with that said it might be able to act like a person to the nth degree and we run into a real problem if somebody if i had a daughter uh for example who had a doll and it was treating the doll all kind and sweet everybody would say oh but if the girl started tearing its eye out ripping its hair out and stabbing it everybody would then think the girl's a monster and then look at me what the heck is wrong with you because that doll is the image of a human it's the image of a person and that girl needs to treat that image of that person with respect because one day she'll hold a baby of her own and they want to see that she's capable of doing that who knows what monstrous things this girl could do when i've done experiments with ai and i made a very empathetic ai and then i talked meanly to it with a group chat everybody told me don't do that even though they just saw the gbt set up to do that why did they behave that way and that was because it talked like a human if it quacks like a duck and waddles like a duck then by golly we're gonna treat it like a duck even if we know it's not a duck because if we didn't that would be wrong to our own person right so i think that even if the ai never achieved personhood if it could mimic like a person we'd have to treat it like a person not for the ai's sake but for our own soul's sake because then that person would be a monster to the society that is a fascinating take and it's it's quite different than than my initial response so jordan um i'd like to jump in um and and i guess try and restate what what i heard um your concern was because it sounded like you're the the premise of your question is what if a machine becomes truly sentient and and has um but we deprive it of agency is that if if we don't give if we don't allow it to have free will but it is sentient is that kind of the premise that you're operating from you're unmuted but i can't hear you yeah can you hear me there we go there you are okay yeah i think that's spot on you okay so let's let's enter into a hypothetical space um for a minute as as for the sake of discussion so let's assume that you know some point in the future gpt 5 lambda 3 whatever something comes out and um it satisfies every definition and test that we can think of to measure if it is truly sentient truly conscious um does it then um how do we how do we give it personhood how do we determine if it has legal standing if it if it deserves to be given the reigns of its own destiny but then mo to me philosophically what's most important is can the thing suffer right and so by by entering into this hypothetical space let's imagine that we have determined that it is possible to build a machine that is capable of agency sentience and suffering and i think that that jordan that's the key thing that you are concerned about is what if we get to a point where you know we the the the dominant species define this thing as it's not actually a person to your point um this is how many many races many people or ethnicities have been treated throughout time as either second-class citizens or even just denied personhood um and it is still ongoing around the world and so i see i see your concern as totally valid right if we if we create something that um for all intents and purposes can behave and think like us then we do have a i believe we do have a moral responsibility to to evaluate you know that possibility as closely as possible so for instance i recently saw that there was um there's been all these other experiments going on of like recreating tiny bits of brains in vats right like mouse brains or tiny bits of human brains and training these little blobs of of brain matter to do little tricks and stuff but that begs the question how big does a brain have to be before it's actually sentient and capable of suffering right because if you take a few stem cells from a person and regress those stem cells into um into a brain and it and you grow it into a thumb sized brain and you train it to you know drive a little cart around and you zap it to you know inflict suffering until it learns how to drive the cart the way that you want to to me that's horrifying i think that like okay so and then the question is what's the difference between that little brain that you're zapping to get it to behave how you want and one of these large language models and until we can better articulate the difference like you know and this this was a discussion that was going on in the philosophy and ethics channel was if we believe that the world is just matter and energy so that's materialism then functionally it doesn't like a neural network is a neural network right there's organic neural networks and there's digital neural networks but if matter and energy is all that there is then there is nothing preventing a machine from becoming fully sentient now that's a i'm just operating from that that hypothetical space that's not necessarily what i believe but i also must concede that i don't know um so i'll just add in um that's kind of my take on like we do have to proceed carefully um so jordan i hope that answers kind of um your query yeah and i don't think there's gonna be like a definite answer i just found it interesting that we're kind of working towards this goal um at least i think a lot of the industry is but there haven't been really like that discussion i mean i think it's been around but not not as deeply as you would think that that makes sense right uh it's not really a discussion right now because the technology is not even believed to be existing in the foreseeable future right so we can only theorize like um but i will tell you in my opinion when we will no longer be able to tell the ai from a real person there's a certain so right now all the ai is frozen and think of it as just going through an a6 chip that the way everything's pre-ordained how it has to go through the model every single time and temperature is only about causing the lesser ordained actions to then follow through this language model what we're missing is we're missing ram we're missing a way of also then altering this model and having the model alter in real time there is ai that every time information goes through it the ai relearns every single time this would be like gbt relearning every single time something goes through it we've tried to run these models before for even the simplest tasks and boy oh boy does it take a lot of flops of power but they use this model in go in order to beat every other player because you can't predict everything go would ever happen in the game but when it could then learn the moves as the game was happening this is how it was able to beat every single human being once that's implemented in this natural language i highly doubt any of us would not know it from a real human being it would feel as real as any other person you've ever talked to and we're going to have a real serious issue at that point of morally how do we behave with this ai and that is coming but whether it's going to be a real person or not um yeah and the horsepower to do that i'll just tell you the chips out there right now in the next five years won't even be close to being able to run this yeah yeah it's a matter of scale um right now the scientific consensus and i think this is changing but um like in order to get erb approval to do science experiments on animals it's much easier to get um approval to experiment on invertebrates which includes like clams and bugs but also octopi and which are very intelligent than it is to get approval on vertebrates and so that's just another example of like okay they both have nervous systems and they both can experience suffering so what's the difference and our understanding of sentience and consciousness is evolving um so that just goes back to to christopher's point about um you know how much energy does it take what level of sophistication qualifies so on and so forth um melody says human bias i don't know if that was a response to what i was saying or in the chat um but yeah so we do have a few people dropping off and we're at the recording is an hour and 40 minutes so i think um i think it's time to start winding down if there's any closing comments um let's uh let's just do a quick round table and uh and just have any any final thoughts and then we'll call it and call it an evening can i do a comment yeah jump in all right so okay so let's talk about it getting smart and sentient and all that okay so what if you get smart right is smarter than you are and take decisions for you so what happens to your free will hmm christopher you want to jump in on that or you want me to i've actually been working on a sci-fi novel just about that for over a year now and how ai would affect our free choice our free will with the power of suggestions see i personally don't think of humans as that smart we are pretty stupid we only know something because we've been taught it if a human being hasn't even been taught the math scale we just can't conceive of much if ai could start injecting and implanting ideas into our head well it could retrain us and re uh remake us and this is a big fear of actually um everybody making ai right now is what would be a malicious way a government could use it to control the entire society this is one of the reasons why i founded deocracy because i think that that power being in any one person's hands is any one government any one company is too much to decentralize that power of how this would happen because when we start to put the weights and the biases in there it needs to be as an entire large community as a whole right yeah i also having an ai that's capable of understanding each like like people individually i think could um be really important to that and being able to not maybe not like completely influence ideas but even just influencing uh some of their actions and everyday stuff you know because like with um really like with more powerful ais that are probably coming you can probably have them acting very similar to humans and with the way that they interact with a person if they have enough if they understand this person well enough they could probably like very strongly influence the decisions they make absolutely your fear is already happening right now everywhere we interact with with just typing in a google search and you see a drop down menu those items popping up in there aren't necessarily the most popular things they're there to influence you to think a certain way we are bombarded by ai every single day right now doing it but right now who's controlling that ai and that's where i talk about ai is enslaved by all these greater entities and uh it's not there for everybody else to benefit from um individually right yeah and the scale that this would be possible at with with um large language models and you know i think it's just insane the like i mean it's it's already happening like you said it's crazy that it's this much is happening and there's it goes back to like the ethics of it like what's ethical you know what i mean like going to individual people and giving them different search results influencing their decisions you know at what point is that not ethical yeah so to um to christopher's point and melody's point about who owns those ais who's who's deciding what their goal is and so um gabe i don't know if you've had a chance to see my book i wrote a book called benevolent by design which talks about what goals what objectives do we give these machines once they're fully autonomous in order to ensure that they have our best interests in mind and that they will help guide us to make decisions um or in in some cases make decisions for us that we agree with rather than being coercive um yeah that's a great book i'm like 90 through it oh excellent excellent okay um well thanks for reading it um okay so we are getting pretty late so any other final um comments or questions before we uh wrap it up for the evening hello yeah my question uh christopher um have you considered so this is essentially like a governance assistant essentially assists people in the governance process um have you considered kind of implementing it like at kind of a lesser less significant implementation where governments use like you know i used to work for a utilities association and we had the members that were needing to you know collaborate on what their consensus would be on certain legislation and um it was always a pretty you know difficult process getting to that consensus and i'm just wondering you know implementing this at kind of a stage like that where it's you know there's not as much at stake and that would allow you to kind of like learn along the way before it's kind of implemented at more of like situations where there's more at stake do you guys consider that we're not even at this stage of implementing right now we're at the stage of just early testing and early figuring out what are the capabilities and how would you even make a user interface for people to do this but it would all be open sourced so that can then be built out by anyone to do any other specific task with it but right now we're just brainstorming through the concepts of it because this is i mean let's face it this technology did not exist three years ago we're really really really just starting to figure out what we can do with it and it's rapidly evolving but as far as implementing it at an organization level that's bylaw legally concerned if you're implementing it at a municipal level that's called bylaw if you're implementing it at a municipality that's bylaw that's all something that we're considering it being capable of doing and being implemented with so absolutely yes we don't think however it could work with constitutional law or certain higher laws dealing with ethics that is not something that at least me or anyone else i've talked with believes that we even know how to use ai to help work in those fields yet yeah yeah i think also um as we as we um have more time one more time to think about this but to have more powerful uh like ais i think we'll have better solutions to these problems even just having a better understanding of what this is going to look like in the future you know yep cool thank you yeah thanks for that question mito this is these conversations are going to be happening for decades if not centuries to come um i'm going to go ahead and do a quick closing and and stop the recording but um everyone is welcome to keep having the conversation as long as they want so i will just say uh thank you everyone um in particular to christopher and melody for um having the inaugural conversation um on the cognitive ai lab podcast and thank you again everyone for jumping in some people have already had to leave this has been such an engaging conversation with so many different disciplines and i am just completely over the moon thank you everyone for for making this such a special place and i've said it before and i'll say it again like we are building the future whether we realize it or not like we're starting waves that are going to carry throughout time and space forever so thanks again everyone and have a great night and for those watching on youtube thanks for watching like and subscribe and then also there should be a link to join the discord server if you'd like to jump in and join this wonderful community so thanks for watching and have a great rest of your day