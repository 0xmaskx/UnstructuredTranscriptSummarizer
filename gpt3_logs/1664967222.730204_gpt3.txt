The following is an unstructured video transcript by David Shapiro. List the most interesting topics from this transcript.

TRANSCRIPT:

virtues and these are the ethics that i try and adhere to and so on the one hand you can have you know a break or a filter that's going to prevent aberrant behavior and then you can also have on the other hand you can have a set of principles or values that you try and and hold to at all times now as with all things you know the ability to engage with a very um dynamic world is really deeply um i'm not going to say problematic it's a difficult problem so that's that's where my research is currently going in terms of okay in general we know that like if you cause harm if you if you hurt someone you're probably gonna get in trouble so don't do that and that's why for instance in my artificial cognition research the very first heuristic imperative is reduced suffering because in general if you cause suffering you're going to get in trouble but if you don't cause suffering you know by either reducing suffering or avoiding it by choosing actions that do not increase suffering you're generally speaking going to be in better shape than if you do the opposite so that's that's kind of where where we're at right now at least in terms of my research can i piggyback off of that and i think this might answer the liability issue and it's an issue because the technology doesn't quite exist to create liability in the way we would like it so these frozen language models that we're creating um there's a big problem with them as we add more and more parameters to them stuff fizzles out we don't do this as human beings if i teach you what a triangle is that it has a triangle looks like this i could people could come and tell you later on this is a triangle no this is a triangle no this is a triangle and you would say nonsense you're all wrong because you've solidified and frozen in your head what a triangle is when we do these frozen models they're only frozen one time but if there was every time there was a different way that the triangle would have been explained it would rethink what that triangle is we need a way of solidifying in the model freezing once and for all this is fact this is it and then we can add in new information and freeze that add in new information but every time we try to add in new information it overrides the other information in order to do liability we would need to freeze in information that these are the ideals this is the behavior that we're looking for these are facts that are not up for negotiation that a triangle is the shape and when we can start doing that then we can talk about liability as we lock it in this is actively in development from multiple companies right now i hope that kind of answers why we can't go into liability until we can freeze um in a knowledge a fact or an ability in it without it changing so i i have i mean my question was actually also around the liability the the library there was more of a comment actually i guess so the way i would see it is that people still have personal responsibility as well so i think the example around like well you know you invest a hundred thousand dollars and the ai does something stupid or something like that ultimately i mean it's a matter of trust right if you trust that the ai is going to do the right thing um you you say okay fine go ahead and do that right it's money that you can you know you can you can spend and you can lose if you need to right but if if that's not the case then you have to make your own decision saying look this is what i want to do this is not what i want to do and if if that so it's a matter of to me it's a matter of trust before you are going to be able to hand that completely over autonomously to that ai um the other question the other question i had was around like just now you mentioned about like the freezing the rules and i think earlier on you mentioned something like that as well but if you if you're talking about society as a whole and the rules around that society changes those roles may change as well what right now is being concerned wait wait wait wait that when we talk about freezing i'm talking about freezing like one two three four it's never one two eight thirteen three if that was introduced to it it would then just bring it in i'm talking about freezing proofs math facts just try to mess with gpt try to ask a mathematical question like um just type this in today is this date what day will it be in 180 days and you'll find out it will whack but if you asked a natural language programming model from like say wolfram alpha it'll get it right because it has frozen into it a model of how to do science but gpt can't do this we need to end up freezing in certain things in it no these do not change in society i'm talking about fundamental things that never change that does get changed in the natural language and that's a problem when because now it um it gets it fizzles out i'm over generalizing and summarizing but does this kind of make any sense you get this barrier that we can't pass as we keep on adding in new information facts are more or less forgotten i'm trying to use it really simple language right yeah sure sure and i think maybe i was misunderstanding it initially but having having said that i think i mean if you look at for example from a science perspective uh yes there are rules that are considered you know fact that it's not going to change but if let's say you did it a couple hundred years ago uh with isaac newton and then einstein comes along and some of that is now changed right some of those rules may or may not apply or there may be a more a different explanation for what's happening there right so those kind of things would still be even though you know at the time and in general it may be considered yeah that's the way it works you know gravity you drop an apple it falls to the ground right but the the underlying things uh like the science underneath that may get more detailed may get more explanation more i don't know it may change some of these things right


LIST OF TOPICS:
-

==========

Reducing or avoiding suffering
-The difficulty of creating liability in AI
-The need to freeze certain information or rules in order to create liability
-The personal responsibility of individuals when using AI
-The possibility that underlying science may change over time